{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afd9470a",
      "metadata": {
        "id": "afd9470a"
      },
      "source": [
        "# RFC obtaintion (RFC format validation and name cleaning)\n",
        "The goal is to read a csv file with 3 columns (\"RFC\", \"RAZON\" and \"AÑO\"), then to validate RFC format, to clean column \"RAZON\" by applying Regex techniques to save the cleaned text in column \"NOMBRE\", and to add column \"PERSON\" if the RFC corresponds to a \"fisica\" or \"moral\" person. Finally, a SLM is implementd to tokenizate and lemmatizate the text in column \"NOMBRE\" and group by this text similarity. The cleaned DataFrame is saved as \"NuevoRFC.csv\". This DataFrame can be concated to other DataFrame (optional).\n",
        "\n",
        "**Remark:** This Jupyter Notebook can be run in Google-Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WGefWejpHYPH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGefWejpHYPH",
        "outputId": "456a8618-3d4a-4877-84aa-e401c6e1b9f0"
      },
      "outputs": [],
      "source": [
        "%pip install thefuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f4def0",
      "metadata": {
        "id": "32f4def0"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import Optional\n",
        "import re\n",
        "import spacy # Recommended for Spanish\n",
        "from rapidfuzz import fuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7826b0e",
      "metadata": {
        "id": "b7826b0e"
      },
      "source": [
        "## Read non-processed csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_C_r8YOAYjko",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_C_r8YOAYjko",
        "outputId": "2af1ac5c-6777-4543-b0a1-0a7ea2c98701"
      },
      "outputs": [],
      "source": [
        "column_names = ['RFC','RAZON','AÑO']\n",
        "year = 2025\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'RFC': ['AAA08091161A', 'AAA1002249W5', 'AAA090924HJ4', 'AVM090924HJ4',\n",
        "            'AAA1002249W6', 'AAA1002249W7', 'BBB08091161A', 'FEM1002249W5',\n",
        "            'BBV08091161A', 'AAA1002249W8', 'AAA1002249W9', 'AAA1002249W1',\n",
        "            'AAA1002249W2', 'BBB08091161A', 'FEM1002249W5', 'AAA1002249W5',\n",
        "            'AVM090924HJ4'],\n",
        "    'RAZON': ['APOYANDO A ANGELITOS CON AUTISMO, A. C.',\n",
        "              'LA PASADITA',\n",
        "              'ARGUELLES, ALVAREZ & ASOCIADOS SA DE CV',\n",
        "              'ADMINISTRATIVAS APLICACIONES AVM SC',\n",
        "              'ADAIR ALONSO ARQUITECTOS SA DE CV',\n",
        "              'Waltmart',\n",
        "              'BBVA BANCOMER',\n",
        "              'COCA COLA FEMSA CV',\n",
        "              'BANCOMER BBVA S.A.',\n",
        "              'Waltmart de Mexico',\n",
        "              'apoyando angelitos con autismo ac',\n",
        "              'MC SA DE CV',\n",
        "              'S.A. DE C.V. MC',\n",
        "              'BBVA BANCOMER',\n",
        "              'FEMSA COCA-COLA',\n",
        "              'ABARROTES LA PASADITA',\n",
        "              'AGROINDUSTRIAS APLICACIONES ADMINISTRATIVAS AVM SC',]\n",
        "})\n",
        "\n",
        "# Add year\n",
        "df['AÑO'] = year\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e19a9ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2e19a9ef",
        "outputId": "3ac62b8e-d5bc-4bd8-e82a-1fb378eed418"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "csv_file = 'prueba.csv'\n",
        "column_names = ['RFC','RAZON','AÑO']\n",
        "df = pd.read_csv(csv_file, sep=',', header=None, names=column_names)\n",
        "df.head(5)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951a2b41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "951a2b41",
        "outputId": "88873f45-3ebd-4dd8-de7d-3515c5647eb1"
      },
      "outputs": [],
      "source": [
        "initial_rows = df.shape[0]\n",
        "print(f\"El archivo tiene {initial_rows} filas.\")\n",
        "\n",
        "# Delete all rows with null values in some columns\n",
        "df = df.dropna()\n",
        "\n",
        "# Change column types\n",
        "df[column_names] = df[column_names].astype('str')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d99a7290",
      "metadata": {
        "id": "d99a7290"
      },
      "source": [
        "## Validate RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f55aeb",
      "metadata": {
        "id": "84f55aeb"
      },
      "outputs": [],
      "source": [
        "# Regular expressions\n",
        "RFC_FISICA_REGEX = re.compile(\n",
        "    r\"^[A-ZÑ&]{4}\"\n",
        "    r\"\\d{2}(0[1-9]|1[0-2])\"\n",
        "    r\"(0[1-9]|[12]\\d|3[01])\"\n",
        "    r\"[A-Z0-9]{3}$\"\n",
        ")\n",
        "\n",
        "RFC_MORAL_REGEX = re.compile(\n",
        "    r\"^[A-ZÑ&]{3}\"\n",
        "    r\"\\d{2}(0[1-9]|1[0-2])\"\n",
        "    r\"(0[1-9]|[12]\\d|3[01])\"\n",
        "    r\"[A-Z0-9]{3}$\"\n",
        ")\n",
        "\n",
        "def normalize_rfc(rfc: str) -> str:\n",
        "    \"\"\"Limpia espacios y convierte a mayúsculas\"\"\"\n",
        "    return rfc.strip().strip(\".\").strip().upper()\n",
        "\n",
        "# Normalize RFC\n",
        "df['RFC'] = df['RFC'].apply(normalize_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5e212d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9d5e212d",
        "outputId": "41bae7f6-5282-41f3-afbe-5a1487d7b14f"
      },
      "outputs": [],
      "source": [
        "def is_persona_fisica(rfc: str) -> bool:\n",
        "    \"\"\"Verifica si el RFC corresponde a persona física\"\"\"\n",
        "    return bool(RFC_FISICA_REGEX.match(rfc))\n",
        "\n",
        "\n",
        "def is_persona_moral(rfc: str) -> bool:\n",
        "    \"\"\"Verifica si el RFC corresponde a persona moral\"\"\"\n",
        "    return bool(RFC_MORAL_REGEX.match(rfc))\n",
        "\n",
        "\n",
        "def get_rfc_type(rfc: str) -> Optional[str]:\n",
        "    \"\"\"Validate RFC\"\"\"\n",
        "\n",
        "    if is_persona_fisica(rfc):\n",
        "        return \"FISICA\"\n",
        "    if is_persona_moral(rfc):\n",
        "        return \"MORAL\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# Validate RFC\n",
        "df['PERSONA'] = df['RFC'].apply(get_rfc_type)\n",
        "\n",
        "# Filter\n",
        "df = df[(df['PERSONA'] == 'FISICA') | (df['PERSONA'] == 'MORAL')]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YHGyWbGNIUF9",
      "metadata": {
        "id": "YHGyWbGNIUF9"
      },
      "source": [
        "This process is applied to \"MORAL\" persons only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9mK4fGuCIFoG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mK4fGuCIFoG",
        "outputId": "ae807faf-4a2b-4bb2-cfac-86350269b3c9"
      },
      "outputs": [],
      "source": [
        "df = df[df['PERSONA'] == 'MORAL']\n",
        "\n",
        "final_rows = df.shape[0]\n",
        "print(f\"El archivo tiene {final_rows} RFCs válidos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a164010c",
      "metadata": {
        "id": "a164010c"
      },
      "source": [
        "## Column \"RAZON\" preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f901add1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f901add1",
        "outputId": "207aedbb-0224-4fb9-8100-da68a2094e69"
      },
      "outputs": [],
      "source": [
        "def normalize_text(text: str, pattern: str, new_value: str) -> str:\n",
        "    \"\"\"Delete trash from text\"\"\"\n",
        "    text = str(text).strip(\".,; \").replace(\",\", \"\").replace(\";\", \"\").replace(\".\", \"\").upper()\n",
        "    text = re.sub(pattern, new_value, text)\n",
        "    text = re.sub(r'[/\\\\-]', ' ', text)\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Patterns like S.A., C.V.\n",
        "norm_rules = {\n",
        "    r'\\bS\\.?\\s?A\\.? ': \"SA \",\n",
        "    r'\\bS\\.?\\s?A\\.?\\b': \"SA\",\n",
        "    r'\\bC\\.?\\s?V\\.?\\b': \"CV\",\n",
        "    r'\\bS\\.?\\s?C\\.?\\b': \"SC\",\n",
        "    r'\\bS\\.?\\s?A\\.?P\\.?\\s?I\\.?\\s?\\b': \"SAPI \",\n",
        "    r'\\bA\\.?\\s?C\\.? ': \"AC \",\n",
        "    r'\\bA\\.?\\s?C\\.?\\b': \"AC\",\n",
        "}\n",
        "\n",
        "# Normalize \"RAZON\"\n",
        "df['NOMBRE'] = df[column_names[1]]\n",
        "\n",
        "for pattern, replacement in norm_rules.items():\n",
        "    df['NOMBRE'] = df['NOMBRE'].apply(\n",
        "        normalize_text,\n",
        "        pattern=pattern,\n",
        "        new_value=replacement\n",
        "    )\n",
        "\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uLo_mgM8JCxY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLo_mgM8JCxY",
        "outputId": "a4af4652-5e98-405f-cfa4-036a1b35f6d9"
      },
      "outputs": [],
      "source": [
        "# Download the model\n",
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XhRGwMmpHp1R",
      "metadata": {
        "id": "XhRGwMmpHp1R"
      },
      "outputs": [],
      "source": [
        "# Install the model\n",
        "# !pip install \"es_core_news_sm-3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96652532",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "96652532",
        "outputId": "c7c96e7d-f594-4f7a-c73a-8e033363e210"
      },
      "outputs": [],
      "source": [
        "def lemmatize_text(text: str) ->str:\n",
        "    \"\"\"Apply tokenization and lemmatization to the text\"\"\"\n",
        "    # Load the model\n",
        "    nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "    # Tokenization\n",
        "    doc = nlp(text.lower())\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    return ' '.join(lemmas).upper()\n",
        "\n",
        "# Lemmatize\n",
        "df['LEMMA_SPA'] = df['NOMBRE'].apply(lemmatize_text)\n",
        "\n",
        "df[['NOMBRE', 'LEMMA_SPA']].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nwGGiFkSM4ms",
      "metadata": {
        "id": "nwGGiFkSM4ms"
      },
      "source": [
        "## Group by words simility with SLM (Small Language Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GCperT5jMzLe",
      "metadata": {
        "id": "GCperT5jMzLe"
      },
      "outputs": [],
      "source": [
        "# Sort by 'RFC'\n",
        "df = df.sort_values(by=\"RFC\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "def group_by_rfc_and_similarity(df:pd.DataFrame, umbral=80)-> pd.DataFrame:\n",
        "    \"\"\"Reorder df by column \"LEMMA_SPA\" according to rfc and words simility\"\"\"\n",
        "    df_temp = df.copy()\n",
        "    df_temp['group'] = -1\n",
        "    grupo_actual = 0\n",
        "\n",
        "    for i in range(len(df_temp)):\n",
        "        if df_temp.loc[i, 'group'] == -1:\n",
        "            df_temp.loc[i, 'group'] = grupo_actual\n",
        "            rfc_base = df_temp.loc[i, 'RFC']\n",
        "            nombre_base = df_temp.loc[i, 'LEMMA_SPA']\n",
        "\n",
        "            # Compare with all following rows\n",
        "            for j in range(i + 1, len(df_temp)):\n",
        "                if df_temp.loc[j, 'group'] == -1:\n",
        "                    rfc_comparar = df_temp.loc[j, 'RFC']\n",
        "                    nombre_comparar = df_temp.loc[j, 'LEMMA_SPA']\n",
        "                    # If RFC is the same, then group\n",
        "                    if rfc_base == rfc_comparar:\n",
        "                        df_temp.loc[j, 'group'] = grupo_actual\n",
        "                    else:\n",
        "                      # Ignore words order (token_sort_ratio)\n",
        "                      score = fuzz.token_sort_ratio(nombre_base, nombre_comparar)\n",
        "                      if score >= umbral:\n",
        "                          df_temp.loc[j, 'group'] = grupo_actual\n",
        "\n",
        "            grupo_actual += 1\n",
        "\n",
        "    # Order by \"group\" and drop this column\n",
        "    return df_temp.sort_values('group').drop(columns=['group']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W0nYWmZVMzJB",
      "metadata": {
        "id": "W0nYWmZVMzJB"
      },
      "outputs": [],
      "source": [
        "# Group by RFC and text similarity\n",
        "df_ordered = group_by_rfc_and_similarity(df,75)\n",
        "\n",
        "# Reorder columns\n",
        "df1 = df_ordered[['RFC','NOMBRE','PERSONA','AÑO','LEMMA_SPA','RAZON']].copy()\n",
        "\n",
        "# Save DataFrame\n",
        "file_name = f\"NuevosRFC\"\n",
        "# file_name = f\"NuevosRFC_{csv_file.split('.')[0]}\"\n",
        "df1.to_csv(f'{file_name}.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i8L65S1qQtSM",
      "metadata": {
        "id": "i8L65S1qQtSM"
      },
      "source": [
        "### Concat 2 DataFrames (optional)\n",
        "\n",
        "For simplicity, the same DataFrame will be concated to itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-I0NIdg0SlNW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "-I0NIdg0SlNW",
        "outputId": "5b2fbeba-5446-4d6c-f894-7480b98afadb"
      },
      "outputs": [],
      "source": [
        "df2 = df1.copy()\n",
        "df2['AÑO'] = year + 1\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0xySqSeFe3iU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0xySqSeFe3iU",
        "outputId": "d7ce2abd-d5d5-4388-c4f3-57aa95902fda"
      },
      "outputs": [],
      "source": [
        "# Concat DataFrames\n",
        "df_final = pd.concat([df1, df2])\n",
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yBqxdld9fnEK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBqxdld9fnEK",
        "outputId": "6f3cce18-a48d-4ae7-a7fc-7432b6d6ab0f"
      },
      "outputs": [],
      "source": [
        "# Sort by 'RFC'\n",
        "df_final = df_final.sort_values(by=\"RFC\", ascending=True).reset_index(drop=True)\n",
        "df_ordered = group_by_rfc_and_similarity(df_final,75)\n",
        "df_final = df_ordered[['RFC','NOMBRE','PERSONA','AÑO','LEMMA_SPA','RAZON']].copy()\n",
        "print(df_final[['RFC','NOMBRE']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gvoCJr1ue3f7",
      "metadata": {
        "id": "gvoCJr1ue3f7"
      },
      "outputs": [],
      "source": [
        "# Save DataFrame\n",
        "file_name = f\"NuevosRFC_final\"\n",
        "# file_name = f\"NuevosRFC_{csv_file.split('.')[0]}\"\n",
        "df_final.to_csv(f'{file_name}.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efe4b5a",
      "metadata": {
        "id": "2efe4b5a"
      },
      "source": [
        "## Appendix: Spacy Models (Recommended for Spanish)\n",
        "Download the corresponding model from \"https://github.com/explosion/spacy-models/releases/tag/es_core_news_sm-3.8.0\" (\"es_core_news_sm-3.8.0-py3-none-any.whl\" file) manually and paste it in this project. After that, run:\n",
        "```\n",
        "%pip install \"es_core_news_sm-3.8.0-py3-none-any.whl\"\n",
        "```\n",
        "Or run:\n",
        "```\n",
        "python -m spacy download es_core_news_sm\n",
        "```\n",
        "Notice that the model name is different. If your are using \"es_core_news_sm-3.8.0-py3-none-any.whl\", run:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46a3c9b",
      "metadata": {
        "id": "a46a3c9b"
      },
      "outputs": [],
      "source": [
        "# %pip install \"es_core_news_sm-3.8.0-py3-none-any.whl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d1bae1a",
      "metadata": {
        "id": "1d1bae1a"
      },
      "outputs": [],
      "source": [
        "import spacy # Recommended for Spanish\n",
        "from thefuzz import fuzz\n",
        "\n",
        "def calcular_similitud(cadena1, cadena2):\n",
        "    \"\"\"\n",
        "    Compara la similitud de dos cadenas de caracteres y retorna un puntaje de 0 a 100.\n",
        "    Utiliza partial_token_sort_ratio para manejar variaciones en el orden\n",
        "    y nombres que contienen subcadenas parciales.\n",
        "    \"\"\"\n",
        "    # Validamos que ambos sean strings\n",
        "    if not isinstance(cadena1, str) or not isinstance(cadena2, str):\n",
        "        return 0\n",
        "\n",
        "    # Aplicamos el método de comparación difusa\n",
        "    #puntuacion = fuzz.partial_token_sort_ratio(cadena1, cadena2)\n",
        "    puntuacion = fuzz.token_sort_ratio(cadena1, cadena2)\n",
        "\n",
        "    return puntuacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a856f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a856f2f",
        "outputId": "275ebd94-216a-4edc-c73a-c4517dce93e6"
      },
      "outputs": [],
      "source": [
        "text1 = 'ABARROTES LA PASADITA'\n",
        "text2 = 'LA PASADITA'\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Process text\n",
        "doc1 = nlp(text1.lower())\n",
        "doc2 = nlp(text2.lower())\n",
        "\n",
        "# Tokenization and lemmatization\n",
        "lemmas1 = [token.lemma_ for token in doc1]\n",
        "limpio1 = ' '.join(lemmas1)\n",
        "print(limpio1)\n",
        "\n",
        "lemmas2 = [token.lemma_ for token in doc2]\n",
        "limpio2 = ' '.join(lemmas2)\n",
        "print(limpio2)\n",
        "\n",
        "score = calcular_similitud(limpio1, limpio2)\n",
        "print(f\"La calificación de similitud es: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d31dab",
      "metadata": {
        "id": "28d31dab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a42d78e",
      "metadata": {
        "id": "1a42d78e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
